save path : ./save
{'decay': 0.0001, 'epochs': 30, 'evaluate': False, 'gammas': [0.1, 0.1], 'learning_rate': 0.1, 'manualSeed': 3752, 'momentum': 0.9, 'ngpu': 1, 'resume': './save/checkpoint.pth.tar', 'save_path': './save', 'schedule': [15, 24], 'start_epoch': 0, 'test_batch_size': 100, 'test_dir': 'dataset', 'train_batch_size': 100, 'train_dir': 'dataset', 'use_cuda': True, 'use_state_dict': False, 'workers': 16}
Random Seed: 3752
use cuda: True
python version : 3.7.3 (default, Mar 27 2019, 22:11:17)  [GCC 7.3.0]
torch  version : 1.1.0
cudnn  version : 7501
=> network:
 CNN(
  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU(inplace)
  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu2): ReLU(inplace)
  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu3): ReLU(inplace)
  (pool3): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu4): ReLU(inplace)
  (pool4): AdaptiveAvgPool2d(output_size=1)
  (classifier): Linear(in_features=64, out_features=10, bias=True)
)
   module name  input shape output shape  parameter quantity inference memory(MB)       MAdd duration percent
0        conv1    1  28  28   16  28  28                 144               0.05MB    213,248           85.64%
1          bn1   16  28  28   16  28  28                  32               0.05MB     50,176            0.18%
2        relu1   16  28  28   16  28  28                   0               0.05MB     12,544            0.07%
3        conv2   16  28  28   32  28  28                4608               0.10MB  7,200,256            4.65%
4          bn2   32  28  28   32  28  28                  64               0.10MB    100,352            0.09%
5        relu2   32  28  28   32  28  28                   0               0.10MB     25,088            0.03%
6        pool2   32  28  28   32  14  14                   0               0.02MB     25,088            1.69%
7        conv3   32  14  14   64  14  14               18432               0.05MB  7,212,800            2.84%
8          bn3   64  14  14   64  14  14                 128               0.05MB     50,176            0.08%
9        relu3   64  14  14   64  14  14                   0               0.05MB     12,544            0.03%
10       pool3   64  14  14   64   7   7                   0               0.01MB     12,544            1.33%
11       conv4   64   7   7   64   7   7               36864               0.01MB  3,609,536            2.88%
12         bn4   64   7   7   64   7   7                 128               0.01MB     12,544            0.07%
13       relu4   64   7   7   64   7   7                   0               0.01MB      3,136            0.03%
14       pool4   64   7   7   64   1   1                   0               0.00MB          0            0.21%
15  classifier           64           10                 650               0.00MB      1,270            0.20%
=============================================================================================================
total parameters quantity: 61,050
total memory: 0.65MB
total MAdd: 18,541,302

=> no checkpoint found at './save/checkpoint.pth.tar'

==>>[2019-05-29 12:33:00] [Epoch=000/030] [Need: 00:00:00] [learning_rate=0.1000] [Best : Accuracy=0.00]
  **Train** Prec@1 94.590 Prec@5 99.282
  **Test** Prec@1 97.830 Prec@5 99.970

==>>[2019-05-29 12:33:25] [Epoch=001/030] [Need: 00:12:17] [learning_rate=0.1000] [Best : Accuracy=97.83]
  **Train** Prec@1 98.572 Prec@5 99.992
  **Test** Prec@1 98.810 Prec@5 99.970

==>>[2019-05-29 12:33:46] [Epoch=002/030] [Need: 00:10:40] [learning_rate=0.1000] [Best : Accuracy=98.81]
  **Train** Prec@1 98.882 Prec@5 99.992
  **Test** Prec@1 98.720 Prec@5 99.970

==>>[2019-05-29 12:34:03] [Epoch=003/030] [Need: 00:09:28] [learning_rate=0.1000] [Best : Accuracy=98.81]
  **Train** Prec@1 99.060 Prec@5 99.995
  **Test** Prec@1 99.020 Prec@5 99.990

==>>[2019-05-29 12:34:21] [Epoch=004/030] [Need: 00:08:49] [learning_rate=0.1000] [Best : Accuracy=99.02]
  **Train** Prec@1 99.172 Prec@5 99.995
  **Test** Prec@1 98.820 Prec@5 99.970

==>>[2019-05-29 12:34:39] [Epoch=005/030] [Need: 00:08:17] [learning_rate=0.1000] [Best : Accuracy=99.02]
  **Train** Prec@1 99.247 Prec@5 99.997
  **Test** Prec@1 98.710 Prec@5 100.000

==>>[2019-05-29 12:34:57] [Epoch=006/030] [Need: 00:07:48] [learning_rate=0.1000] [Best : Accuracy=99.02]
  **Train** Prec@1 99.322 Prec@5 99.998
  **Test** Prec@1 99.260 Prec@5 99.990

==>>[2019-05-29 12:35:15] [Epoch=007/030] [Need: 00:07:22] [learning_rate=0.1000] [Best : Accuracy=99.26]
  **Train** Prec@1 99.337 Prec@5 99.995
  **Test** Prec@1 99.110 Prec@5 99.970

==>>[2019-05-29 12:35:35] [Epoch=008/030] [Need: 00:07:07] [learning_rate=0.1000] [Best : Accuracy=99.26]
  **Train** Prec@1 99.402 Prec@5 99.998
  **Test** Prec@1 99.220 Prec@5 99.990

==>>[2019-05-29 12:35:53] [Epoch=009/030] [Need: 00:06:43] [learning_rate=0.1000] [Best : Accuracy=99.26]
  **Train** Prec@1 99.392 Prec@5 99.998
  **Test** Prec@1 98.450 Prec@5 99.990

==>>[2019-05-29 12:36:14] [Epoch=010/030] [Need: 00:06:28] [learning_rate=0.1000] [Best : Accuracy=99.26]
  **Train** Prec@1 99.405 Prec@5 99.997
  **Test** Prec@1 98.690 Prec@5 99.970

==>>[2019-05-29 12:36:33] [Epoch=011/030] [Need: 00:06:07] [learning_rate=0.1000] [Best : Accuracy=99.26]
  **Train** Prec@1 99.438 Prec@5 99.997
  **Test** Prec@1 98.460 Prec@5 99.980

==>>[2019-05-29 12:36:50] [Epoch=012/030] [Need: 00:05:44] [learning_rate=0.1000] [Best : Accuracy=99.26]
  **Train** Prec@1 99.503 Prec@5 99.998
  **Test** Prec@1 98.660 Prec@5 99.970

==>>[2019-05-29 12:37:07] [Epoch=013/030] [Need: 00:05:23] [learning_rate=0.1000] [Best : Accuracy=99.26]
  **Train** Prec@1 99.423 Prec@5 99.998
  **Test** Prec@1 99.110 Prec@5 100.000

==>>[2019-05-29 12:37:26] [Epoch=014/030] [Need: 00:05:04] [learning_rate=0.1000] [Best : Accuracy=99.26]
  **Train** Prec@1 99.508 Prec@5 99.997
  **Test** Prec@1 99.060 Prec@5 99.990

==>>[2019-05-29 12:37:44] [Epoch=015/030] [Need: 00:04:43] [learning_rate=0.0100] [Best : Accuracy=99.26]
  **Train** Prec@1 99.762 Prec@5 99.998
  **Test** Prec@1 99.540 Prec@5 100.000

==>>[2019-05-29 12:38:04] [Epoch=016/030] [Need: 00:04:25] [learning_rate=0.0100] [Best : Accuracy=99.54]
  **Train** Prec@1 99.847 Prec@5 99.998
  **Test** Prec@1 99.550 Prec@5 100.000

==>>[2019-05-29 12:38:23] [Epoch=017/030] [Need: 00:04:06] [learning_rate=0.0100] [Best : Accuracy=99.55]
  **Train** Prec@1 99.862 Prec@5 99.998
  **Test** Prec@1 99.530 Prec@5 100.000

==>>[2019-05-29 12:38:41] [Epoch=018/030] [Need: 00:03:47] [learning_rate=0.0100] [Best : Accuracy=99.55]
  **Train** Prec@1 99.863 Prec@5 99.998
  **Test** Prec@1 99.560 Prec@5 100.000

==>>[2019-05-29 12:38:59] [Epoch=019/030] [Need: 00:03:28] [learning_rate=0.0100] [Best : Accuracy=99.56]
  **Train** Prec@1 99.883 Prec@5 99.998
  **Test** Prec@1 99.540 Prec@5 100.000

==>>[2019-05-29 12:39:17] [Epoch=020/030] [Need: 00:03:08] [learning_rate=0.0100] [Best : Accuracy=99.56]
  **Train** Prec@1 99.883 Prec@5 99.998
  **Test** Prec@1 99.520 Prec@5 100.000

==>>[2019-05-29 12:39:35] [Epoch=021/030] [Need: 00:02:49] [learning_rate=0.0100] [Best : Accuracy=99.56]
  **Train** Prec@1 99.923 Prec@5 100.000
  **Test** Prec@1 99.530 Prec@5 99.990

==>>[2019-05-29 12:39:53] [Epoch=022/030] [Need: 00:02:30] [learning_rate=0.0100] [Best : Accuracy=99.56]
  **Train** Prec@1 99.933 Prec@5 100.000
  **Test** Prec@1 99.510 Prec@5 100.000

==>>[2019-05-29 12:40:11] [Epoch=023/030] [Need: 00:02:11] [learning_rate=0.0100] [Best : Accuracy=99.56]
  **Train** Prec@1 99.930 Prec@5 100.000
  **Test** Prec@1 99.560 Prec@5 100.000

==>>[2019-05-29 12:40:30] [Epoch=024/030] [Need: 00:01:52] [learning_rate=0.0010] [Best : Accuracy=99.56]
  **Train** Prec@1 99.935 Prec@5 100.000
  **Test** Prec@1 99.510 Prec@5 100.000

==>>[2019-05-29 12:40:52] [Epoch=025/030] [Need: 00:01:34] [learning_rate=0.0010] [Best : Accuracy=99.56]
  **Train** Prec@1 99.938 Prec@5 100.000
  **Test** Prec@1 99.520 Prec@5 100.000

==>>[2019-05-29 12:41:09] [Epoch=026/030] [Need: 00:01:15] [learning_rate=0.0010] [Best : Accuracy=99.56]
  **Train** Prec@1 99.940 Prec@5 100.000
  **Test** Prec@1 99.530 Prec@5 100.000

==>>[2019-05-29 12:41:27] [Epoch=027/030] [Need: 00:00:56] [learning_rate=0.0010] [Best : Accuracy=99.56]
  **Train** Prec@1 99.943 Prec@5 100.000
  **Test** Prec@1 99.520 Prec@5 100.000

==>>[2019-05-29 12:41:46] [Epoch=028/030] [Need: 00:00:37] [learning_rate=0.0010] [Best : Accuracy=99.56]
  **Train** Prec@1 99.950 Prec@5 100.000
  **Test** Prec@1 99.490 Prec@5 100.000

==>>[2019-05-29 12:42:03] [Epoch=029/030] [Need: 00:00:18] [learning_rate=0.0010] [Best : Accuracy=99.56]
  **Train** Prec@1 99.943 Prec@5 100.000
  **Test** Prec@1 99.560 Prec@5 100.000
  **Test** Prec@1 99.560 Prec@5 100.000
validate function took 3350.702 ms
